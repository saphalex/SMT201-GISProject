<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-04-06">

<title>Pavement vs Peat – GIS Group 6: Pavement vs Peat</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a78bc22c21c5275f96438b53095d57b2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">GIS Group 6: Pavement vs Peat</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Abstract</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./scope.html"> 
<span class="menu-text">Project Scope</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./data.html"> 
<span class="menu-text">Data Analysis</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./methodology.html"> 
<span class="menu-text">Methodology</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./webmaps.html"> 
<span class="menu-text">Web Maps</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./lessons.html"> 
<span class="menu-text">Recommendations &amp; Lessons</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./poster.html"> 
<span class="menu-text">Poster</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Team</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#step-by-step" id="toc-step-by-step" class="nav-link active" data-scroll-target="#step-by-step">Step-by-Step</a>
  <ul class="collapse">
  <li><a href="#viewing-all-sentinel-2-satellite-data-for-kl-for-2020-2024" id="toc-viewing-all-sentinel-2-satellite-data-for-kl-for-2020-2024" class="nav-link" data-scroll-target="#viewing-all-sentinel-2-satellite-data-for-kl-for-2020-2024">1.1 Viewing all Sentinel-2 satellite data for KL for 2020-2024</a></li>
  <li><a href="#downloading-datasets" id="toc-downloading-datasets" class="nav-link" data-scroll-target="#downloading-datasets">1.2 Downloading datasets</a></li>
  <li><a href="#data-extraction-and-preprocessing" id="toc-data-extraction-and-preprocessing" class="nav-link" data-scroll-target="#data-extraction-and-preprocessing">2 Data Extraction and Preprocessing</a>
  <ul class="collapse">
  <li><a href="#creating-project" id="toc-creating-project" class="nav-link" data-scroll-target="#creating-project">2.1 Creating Project</a></li>
  <li><a href="#extracting-kl-shapefile" id="toc-extracting-kl-shapefile" class="nav-link" data-scroll-target="#extracting-kl-shapefile">2.2 Extracting KL shapefile</a></li>
  <li><a href="#extracting-kl-map-from-sentinel-2-data" id="toc-extracting-kl-map-from-sentinel-2-data" class="nav-link" data-scroll-target="#extracting-kl-map-from-sentinel-2-data">2.3 Extracting KL map from Sentinel-2 data</a></li>
  </ul></li>
  <li><a href="#processing-remote-sensing-images" id="toc-processing-remote-sensing-images" class="nav-link" data-scroll-target="#processing-remote-sensing-images">3 Processing Remote Sensing Images</a>
  <ul class="collapse">
  <li><a href="#creating-true-composite-images-and-false-composite-images-from-extracted-images" id="toc-creating-true-composite-images-and-false-composite-images-from-extracted-images" class="nav-link" data-scroll-target="#creating-true-composite-images-and-false-composite-images-from-extracted-images">3.1 Creating True Composite Images and False Composite Images from extracted images</a></li>
  <li><a href="#using-scp-plugin-to-do-supervised-classification-for-the-map-categorising-by-various-land-cover-types" id="toc-using-scp-plugin-to-do-supervised-classification-for-the-map-categorising-by-various-land-cover-types" class="nav-link" data-scroll-target="#using-scp-plugin-to-do-supervised-classification-for-the-map-categorising-by-various-land-cover-types">3.2 Using SCP plugin to do supervised classification for the map, categorising by various land cover types</a></li>
  <li><a href="#conducting-accuracy-assessment-for-trained-model" id="toc-conducting-accuracy-assessment-for-trained-model" class="nav-link" data-scroll-target="#conducting-accuracy-assessment-for-trained-model">3.3 Conducting Accuracy Assessment for trained model</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Pavement vs Peat</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Anne Saphrin Alex Sathyan, Harshitha Balaji, Lau Liang Jun </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 6, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">April 19, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="step-by-step" class="level1">
<h1>Step-by-Step</h1>
<section id="viewing-all-sentinel-2-satellite-data-for-kl-for-2020-2024" class="level3">
<h3 class="anchored" data-anchor-id="viewing-all-sentinel-2-satellite-data-for-kl-for-2020-2024">1.1 Viewing all Sentinel-2 satellite data for KL for 2020-2024</h3>
<p>Why Sentinel-2 over Landsat8 for Land Cover Change Analysis?</p>
<p>Both Sentinel-2 and Landsat 8 data are excellent, but Sentinel-2 is preferred for land cover mapping, especially for dynamic urban areas like Kuala Lumpur and its 10m resolution better captures smaller urban features like roads and buildings, as well as fine-scale deforestation. Landsat 8’s 30m resolution often mixes land covers like trees and roads together, causing misclassification.</p>
<p>However, since Sentinel-2 is a relatively newer system, for long-term studies, Landsat has a much larger archive, and 30m resolution would be sufficient if the study was on a continental/much larger scale, requiring large area mapping.</p>
<ul>
<li><p>Visit Copernicus website at <a href="https://dataspace.copernicus.eu/" class="uri">https://dataspace.copernicus.eu/</a></p></li>
<li><p>Register for an account if you do not have one</p></li>
<li><p>Go to the Copernicus Browser and log in</p></li>
<li><p>You will be brought to this page</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 4.29.38 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>Hover over <img src="images/Screenshot 2025-04-19 at 4.31.29 PM.png" class="img-fluid" width="81">at the top right and change Basemaps to OSM Background</p></li>
<li><p>Drag and zoom in to your location of interest, Kuala Lumpur</p></li>
<li><p>Hover&nbsp;over <img src="images/Screenshot 2025-04-19 at 4.33.36 PM.png" width="43" height="38"> and click <img src="images/Screenshot 2025-04-19 at 4.34.35 PM.png" width="43" height="37">.</p></li>
<li><p>Select and draw a rectangle, covering the area of Kuala Lumpur completely</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 4.37.16 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>On the left of the screen, select the SEARCH tab</p></li>
<li><p>Check SENTINEL-2, MSI, L2A, and drag the cloud cover to 50% (this is to only show images that have less than 50% of the image covered by clouds)</p>
<p>The reason only L2A is check is because it is atmospherically corrected and a cloud mask layer is added, with improved accuracy for ground features as compared to class L1C.</p>
<p><img src="images/Screenshot 2025-04-19 at 4.39.35 PM.png" class="img-fluid"></p></li>
<li><p>Scroll down and select the TIME RANGE</p>
<ul>
<li><p>From: 01-01-2020</p></li>
<li><p>To: 31-12-2020</p></li>
</ul></li>
</ul>
<p>Click on SEARCH</p>
<p><img src="images/Screenshot 2025-04-19 at 4.50.18 PM.png" class="img-fluid" width="1000"></p>
<ul>
<li>You will see that Kuala Lumpur is covered by two rectangles, indicating that the location is covered by two different satellite images. By clicking each of the rectangle, you will see the relevant images that are covering that specific area.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Screenshot 2025-04-19 at 4.52.45 PM.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1000"></p>
</figure>
</div>
<ul>
<li>Click on the <img src="images/Screenshot 2025-04-19 at 4.55.06 PM.png" class="img-fluid" width="43">icon to have a clearer view of the image.</li>
</ul>
</section>
<section id="downloading-datasets" class="level3">
<h3 class="anchored" data-anchor-id="downloading-datasets">1.2 Downloading datasets</h3>
<section id="select-and-download-satellite-data-with-lowest-cloud-cover-and-temporal-consistency" class="level4">
<h4 class="anchored" data-anchor-id="select-and-download-satellite-data-with-lowest-cloud-cover-and-temporal-consistency">1.2.1 Select and download satellite data with lowest cloud cover and temporal consistency</h4>
<p>To choose suitable images for temporal analysis in this study, we should be prioritising similar acquisition dates and low cloud cover. Having similar acquisition dates (images from around the same month per year, e.g.&nbsp;March) allows us to compare same-season images to minimise seasonal effects like monsoon season and ensure there is sufficient time between years for land cover change to happen (e.g.&nbsp;images from November 2020 and January 2021 would be relatively similar as only 3 months has passed, and no meaningful information can be extracted). Prioritise low to no cloud cover to ensure that the ground area is visible and are not covered by clouds and their shadows. Also, both images that piece to form Kuala Lumpur should be as close to the same date as possible, to ensure consistent image.</p>
<ul>
<li><p>Take note of usable images, then compare them across the years, before selecting images of similar months to be used for analysis.</p></li>
<li><p>For this study, we have chosen the following images:</p></li>
<li><p>2020: 28 Feb 500 (M) 28 Feb 500 (R)</p>
<ul>
<li><p>S2A_MSIL2A_20200228T032701_N0500_R018_T47NQD_20230627T090641.SAFE</p></li>
<li><p>S2A_MSIL2A_20200228T032701_N0500_R018_T47NRD_20230627T090641.SAFE</p></li>
</ul></li>
<li><p>2021: 07 Feb 500 (M) 07 Feb 500 (R)</p>
<ul>
<li><p>S2B_MSIL2A_20210207T032919_N0500_R018_T47NQD_20230519T060502.SAFE</p></li>
<li><p>S2B_MSIL2A_20210207T032919_N0500_R018_T47NRD_20230519T060502.SAFE</p></li>
</ul></li>
<li><p>2022: 13 Jan 510 (M) 13 Jan 510 (R)</p>
<ul>
<li><p>S2B_MSIL2A_20220113T033109_N0510_R018_T47NQD_20240428T204639.SAFE</p></li>
<li><p>S2B_MSIL2A_20220113T033109_N0510_R018_T47NRD_20240428T204639.SAFE</p></li>
</ul></li>
<li><p>2023: 9 March 510 (M) 14 March 510 (R)</p>
<ul>
<li><p>S2B_MSIL2A_20230309T032559_N0510_R018_T47NQD_20240823T055939.SAFE</p></li>
<li><p>S2A_MSIL2A_20230314T032511_N0510_R018_T47NRD_20240820T175125.SAFE</p></li>
</ul></li>
<li><p>2024 27 Feb 510 (M) 27 Feb 510 (R)</p>
<ul>
<li><p>S2A_MSIL2A_20240227T032711_N0510_R018_T47NQD_20240227T074952.SAFE</p></li>
<li><p>S2A_MSIL2A_20240227T032711_N0510_R018_T47NRD_20240227T074952.SAFE</p></li>
</ul></li>
<li><p>To download, click on the <img src="images/Screenshot 2025-04-19 at 5.27.47 PM.png" class="img-fluid" width="43">&nbsp;icon. The file size is relatively big, so it may take some time.</p></li>
</ul>
</section>
<section id="downloading-kl-dataset" class="level4">
<h4 class="anchored" data-anchor-id="downloading-kl-dataset">1.2.2 Downloading KL dataset</h4>
<ul>
<li><p>Visit <a href="https://www.geoboundaries.org" class="uri">https://www.geoboundaries.org</a></p></li>
<li><p>Go to ’Individual Country Files –&gt; Single Country –&gt; Files Type in Malaysia</p></li>
<li><p>Download the last 2 datasets from 2020 and 2021</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 5.35.20 PM 1.png" class="img-fluid" width="1000"></p></li>
</ul>
</section>
</section>
<section id="data-extraction-and-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-extraction-and-preprocessing">2 Data Extraction and Preprocessing</h2>
<section id="creating-project" class="level3">
<h3 class="anchored" data-anchor-id="creating-project">2.1 Creating Project</h3>
<ul>
<li><p>From Window Desktop, launch QGIS</p>
<ul>
<li>You will start a new QGIS project.</li>
</ul></li>
<li><p>From the menu bar, select ‘Project –&gt; New’</p></li>
<li><p>Select ‘Project –&gt; Save As..’ ,&nbsp; create a project name and ensure it is saved in QGIS XML Project format (*.QGIS)</p></li>
</ul>
</section>
<section id="extracting-kl-shapefile" class="level3">
<h3 class="anchored" data-anchor-id="extracting-kl-shapefile">2.2 Extracting KL shapefile</h3>
<ul>
<li><p>To add the shapefiles to QGIS, from the menu bar, select ‘Layer’ → ‘Add Layer’ → ‘Add Vector Layer…’</p></li>
<li><p>From the dataset downloaded for 2020, choose the file ‘geoBoundaries-MYS-ADM2_simplified.shp’ and click ‘Add’</p></li>
<li><p>From the dataset downloaded for 2021, choose the file ‘geoBoundaries-MYS-ADM3_simplified.shp’ and click ‘Add’</p></li>
<li><p>Select and view the 2020 layer, then click on the dropdown beside found on the overlay panels, click ‘Select Feature(s)’ and select the KL polygon</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Screenshot 2025-04-19 at 5.49.17 PM.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1000"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Screenshot 2025-04-19 at 5.49.53 PM.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1000"></p>
</figure>
</div>
<ul>
<li><p>Next, right-click the layer  ExportSave selected features as…</p></li>
<li><p>Save it as a Shapefile format named ‘KL’ and change CRS to EPSG:4751, click ‘OK’</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.26.21 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>From the menu bar, select ‘Vector’ → ‘Geoprocessing Tools’ → ‘Clip…’</p></li>
<li><p>Select the 2021 layer as input layer and ‘KL’ as overlay and click OK,&nbsp; you should see the image below. Save it as shapefile called ‘KLMap (with subzone)’. Remove all other layers</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.28.11 PM.png" class="img-fluid" width="1000"></p></li>
</ul>
</section>
<section id="extracting-kl-map-from-sentinel-2-data" class="level3">
<h3 class="anchored" data-anchor-id="extracting-kl-map-from-sentinel-2-data">2.3 Extracting KL map from Sentinel-2 data</h3>
<ul>
<li><p>To add the Sentinel-2 files to QGIS, from the menu bar, select ‘Layer’ → ‘Add Layer’ → ‘Add Raster Layer…’</p></li>
<li><p>Click the ‘…’ button and browse for 2020, the sentinel folder containing&nbsp; the ‘Left’ image of KL, for bands 2, 3, 4 and 8 under the ‘10m’ folder. Click ‘Open’, then click ‘Add’ and ‘Close’. Do so for the ‘Right’ image for KL also. You should be seeing something like that in your screen.</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.46.40 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>We want to combine these two images, so from the menu bar, select ‘Raster’ → ‘Miscellaneous → ‘Build Virtual Raster…’</p></li>
<li><p>Under input layer, click “…”&nbsp;and select two images of the same bands, then click ‘Run’</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.48.02 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>A virtual layer will appear as shown below</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.49.26 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>Next, we will clip out only the area we are interested in, which is the KL area</p></li>
<li><p>From the menu bar, select ‘Raster’ → ‘Extraction’→ ‘Clip Raster by Mask Layer…’</p></li>
<li><p>Put the ‘Virtual’ layer as Input layer and the ‘KLMap (with subzone)’ as Mask layer and click ‘Run’</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.51.40 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>You will then see this</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.53.07 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>Right click the layer → Export → Save As…. Save it in GeoTIFF format called ‘2020-0228-B02’ and remove the clipped and virtual layers</p></li>
<li><p>Do so for all 4 bands for the year</p></li>
</ul>
</section>
</section>
<section id="processing-remote-sensing-images" class="level2">
<h2 class="anchored" data-anchor-id="processing-remote-sensing-images">3 Processing Remote Sensing Images</h2>
<section id="creating-true-composite-images-and-false-composite-images-from-extracted-images" class="level3">
<h3 class="anchored" data-anchor-id="creating-true-composite-images-and-false-composite-images-from-extracted-images">3.1 Creating True Composite Images and False Composite Images from extracted images</h3>
<p>Next, we want to create True and False Composite Images to distinguish urban areas from bare soil and highlighting vegetation:</p>
<ul>
<li><p>From the menu bar, select ‘Plugins’ → ‘Managed and Install Plugins…’, search and install ‘Semi-Automatic Classification Plugin’</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 6.58.10 PM.png" class="img-fluid"></p></li>
<li><p>Once installed, click on <img src="images/Screenshot 2025-04-19 at 6.59.09 PM.png" class="img-fluid" width="43">, and a panel called ‘SCP Dock’ will pop up below the ‘Browser’ panel</p></li>
<li><p>·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Click on <img src="images/Screenshot 2025-04-19 at 6.59.56 PM.png" class="img-fluid" width="43">&nbsp;and a window will pop up. Click on it again and click <img src="images/Screenshot 2025-04-19 at 7.00.33 PM.png" class="img-fluid" width="43">&nbsp;to create a band set. Name the set as ‘2020’ and click <img src="images/Screenshot 2025-04-19 at 7.01.26 PM.png" class="img-fluid" width="43">&nbsp;on the right side and add layers 2,3,4 and 8 into the set. Finally, click <img src="images/Screenshot 2025-04-19 at 7.02.03 PM.png" class="img-fluid" width="43">.</p></li>
<li><p>Going back to the project view, &nbsp;under the same panel, type in ‘3-2-1’ and ‘Enter’ <img src="images/Screenshot 2025-04-19 at 7.03.21 PM.png" width="43" height="8">.</p></li>
<li><p>A Virtual Band Set will pop up, showing the True Composite Image for the band set</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 7.04.30 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>Export the band set as a GeoTIFF image, but change the output mode as a Rendered Image. Save it as ‘2020-TCI’<img src="images/Screenshot 2025-04-19 at 7.08.33 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>Now change the virtual band set to ‘4-3-2’ and you will get a False Colour Composite of the map like this. Save it accordingly too as ‘2020-FCC’</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 7.09.19 PM.png" class="img-fluid" width="1000"><br>
</p></li>
</ul>
</section>
<section id="using-scp-plugin-to-do-supervised-classification-for-the-map-categorising-by-various-land-cover-types" class="level3">
<h3 class="anchored" data-anchor-id="using-scp-plugin-to-do-supervised-classification-for-the-map-categorising-by-various-land-cover-types">3.2 Using SCP plugin to do supervised classification for the map, categorising by various land cover types</h3>
<p>Next, instead of classifying each land cover type manually, we will be training the model to classify it for us. Upon preliminary analysis of both TCI and FCC, we can determine a few land cover types: Natural Vegetation, Managed Vegetation, Water Body, Impervious Surfaces, Built-up 1 (low-rise), Built-up 2 (high-rise), Barren Land, and Shadow</p>
<ul>
<li><p>Under the SCP Dock, go to the ‘Training Input’ tab <img src="images/Screenshot 2025-04-19 at 7.11.20 PM.png" class="img-fluid" width="43"> .&nbsp; Click <img src="images/Screenshot 2025-04-19 at 7.11.52 PM.png" class="img-fluid" width="43">&nbsp;to create a new training input. Name it ‘2020-Train’</p></li>
<li><p>Select&nbsp; <img src="images/Screenshot 2025-04-19 at 7.12.54 PM.png" class="img-fluid" width="43">&nbsp;on the panel near the top of the project to start creating polygons for training. Left click to create points and right click at the end to close off the polygon. At the bottom of the SCP Dock, once you have created the polygon,&nbsp; you should edit the MCID (Macro class index) and the CID (Class index) to classify the area you have selected properly. For example, I have selected an area of forest, I will classify it as follows:</p></li>
<li><p><img src="images/Screenshot 2025-04-19 at 7.13.42 PM.png" class="img-fluid"></p></li>
<li><p>Here are the MCID and CID we have used to group our areas:</p></li>
<li><p>Try to use these as guidelines:</p>
<ul>
<li><p>Number of points should be proportional to the area in the location covered by said MCID (If forest covers 20%, forest should have around 20% the number of points compared to total)</p></li>
<li><p>Try to select far away points even if macro-classes are the same to ensure fair distribution of points and different reflectance values, and left and right of the map (since it is pieced using two separate satellite images (70% L 30% R image)and reflectance might differ slightly)</p></li>
<li><p>Number of points for Training data to test data should be about 70% to 30%</p></li>
<li><p>Try to select a bigger area and not just a few pixels, as it would be hard for the model to distinguish</p></li>
<li><p>After classifying them, to add each polygon into your training input, click <img src="images/Screenshot 2025-04-19 at 7.15.45 PM.png" class="img-fluid" width="43"> and a black area will show in its place, indicating that the area has been cut out.</p></li>
</ul></li>
<li><p>Our Macro classes and Classes identified (with examples):</p>
<ul>
<li><p>Train data</p></li>
<li><p>MCID,CID</p></li>
<li><p>1 Natural Vegetation</p></li>
<li><p>1.1 Forest :</p>
<p><img src="images/Screenshot 2025-04-19 at 7.17.46 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>2 Managed Vegetation</p>
<ul>
<li><p>2.1 Golf course grass</p>
<p><img src="images/Screenshot 2025-04-19 at 7.19.00 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>2.2 Sports field</p>
<p><img src="images/Screenshot 2025-04-19 at 7.19.52 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
<li><p>3 Water Body</p>
<ul>
<li><p>3.1 Flood Reservoir</p>
<p><img src="images/Screenshot 2025-04-19 at 7.21.27 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>3.2 Lakes</p>
<p><img src="images/Screenshot 2025-04-19 at 7.22.21 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>3.3 Rivers</p>
<p><img src="images/Screenshot 2025-04-19 at 7.23.06 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
<li><p>4 Impervious Surfaces</p>
<ul>
<li><p>4.1 Roads:</p>
<p><img src="images/Screenshot 2025-04-19 at 7.24.34 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
<li><p>5 Built-up 1 (low-rise)</p>
<ul>
<li><p>5.1 Houses</p>
<p><img src="images/Screenshot 2025-04-19 at 7.26.12 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
<li><p>6 Built-up 2 (high-rise)</p>
<ul>
<li><p>6.1 Buildings (High-rise buildings are typically accompanied by shadows)</p>
<p><img src="images/Screenshot 2025-04-19 at 7.27.49 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
<li><p>7 Barren Land:</p>
<ul>
<li><p>7.1 Empty Lot —&gt; Super bright reflective surface</p>
<p><img src="images/Screenshot 2025-04-19 at 7.27.49 PM-01.png" class="img-fluid" width="1000"></p></li>
<li><p>7.2 Empty Lot —&gt; Reddish brown empty lots</p>
<p><img src="images/Screenshot 2025-04-19 at 7.30.25 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>7.3 Open soil —&gt; Cemetery/Parks brown land</p>
<p><img src="images/Screenshot 2025-04-19 at 7.31.29 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
<li><p>8 Shadow</p>
<ul>
<li><p>8.1 Shadow —&gt; Select shadow of buildings, trace them to their exact shape</p>
<p><img src="images/Screenshot 2025-04-19 at 7.32.43 PM.png" class="img-fluid" width="1000"></p></li>
</ul></li>
</ul></li>
<li><p>After classifying, try to change the colours for each CID into their own colours and group them, to allow for easier visualisation.</p>
<p><img src="images/Screenshot 2025-04-19 at 7.33.36 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>This is the colour palette used by our group, in order of macro classes, stopping at Black for Shadow.</p>
<p><img src="images/Screenshot 2025-04-19 at 7.34.16 PM.png" class="img-fluid"></p></li>
<li><p>Next, select all the points, and click on <img src="images/Screenshot 2025-04-19 at 7.34.53 PM.png" class="img-fluid" width="43">&nbsp;to see the spectral signature plot for the points</p>
<p><img src="images/Screenshot 2025-04-19 at 7.35.28 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>It will look something like this:</p>
<p><img src="images/Screenshot 2025-04-19 at 7.36.19 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>We can see that for most classes, they are grouped together. However, the red lines(Built-up 1 low-rise Houses) have a wide range of values, which is not what we want, and maybe creating an extra macro class to further classify them or hinting to reselect the polygons. Also, grey(roads), black(shadow) and light blue(water body) have similar values, hinting that they could be misclassified by the model.</p></li>
<li><p>Reminder that whenever you are attempting to add new points to the spectral plot, you should be deleting old ones first, or they may interfere with the data.</p></li>
<li><p>Next, when all the points are chosen and you are satisfied with them,&nbsp; click <img src="images/Screenshot 2025-04-19 at 7.37.18 PM.png" class="img-fluid" width="43">&nbsp;and go back to the SCP dialogue window</p></li>
<li><p>Go to ‘Band ProcessingClassification’ this time and choose the correct band set that you are currently using. Select ‘Linear scaling’ and ‘Macroclass ID’ for training. Click ‘Run’ and save it as ‘2020-Train-data-1’.</p>
<p><img src="images/Screenshot 2025-04-19 at 7.37.55 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>When it is done, a new layer will be added to your project window, showing you the classification of the different land cover types</p>
<p><img src="images/Screenshot 2025-04-19 at 7.39.03 PM.png" class="img-fluid" width="1000"></p></li>
<li><p>Repeat this step until you are satisfied with the classification</p></li>
<li><p>Then, right click ‘SCP training layer’ and export it as shapefile and save it</p></li>
<li><p>Save, then click on <img src="images/Screenshot 2025-04-19 at 7.40.15 PM.png" class="img-fluid" width="43">&nbsp;to create a new set for the Test data called ‘2020-Test’</p></li>
<li><p>Ensure that the training shapefile layer is shown and visible, to ensure that you do not select the same area for both Training and Test</p>
<p><img src="images/Screenshot 2025-04-19 at 7.40.55 PM.png" class="img-fluid"></p></li>
<li><p>Once done, export this layer into a shapefile too, called ‘2020-Test’</p></li>
</ul>
</section>
<section id="conducting-accuracy-assessment-for-trained-model" class="level3">
<h3 class="anchored" data-anchor-id="conducting-accuracy-assessment-for-trained-model">3.3 Conducting Accuracy Assessment for trained model</h3>
<ul>
<li><p>Next, we return to SCP dialogue window after clicking on <img src="images/Screenshot 2025-04-19 at 7.42.55 PM.png" class="img-fluid" width="43"></p></li>
<li><p>Go to ‘Postprocessing —&gt; Accuracy’</p></li>
<li><p>Select the train data file for&nbsp; ‘Select the classification to assess’ and put the shapefile test layer into ‘Select the reference vector or raster’. Click the <img src="images/Screenshot 2025-04-19 at 7.43.55 PM.png" class="img-fluid" width="43">&nbsp;button if the layers are not showing up, and change the ‘Vector field’ to ‘macroclass’. Click ‘Run’ and save it as ‘MLAccuracy2020’. After running, the Accuracy Assessment Report appears, showing 1. Long pair-wise error list 2. Confusion Matrix (Error Matrix) and 3. Kappa Hat Matrix. There will be an overall accuracy and an accuracy for each class.</p>
<p><img src="images/Screenshot 2025-04-19 at 7.45.00 PM.png" class="img-fluid" width="1000"></p></li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>